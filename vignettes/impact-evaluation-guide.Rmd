---
title: "Evaluating Internship Impact on Career Trajectories"
author: "vecshift package"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
    number_sections: true
    fig_width: 8
    fig_height: 6
vignette: >
  %\VignetteIndexEntry{Evaluating Internship Impact on Career Trajectories}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 8,
  fig.height = 6,
  warning = FALSE,
  message = FALSE,
  dpi = 100
)

# Load required packages
library(data.table)
library(vecshift)

# Set random seed for reproducibility
set.seed(2024)
```

# Introduction: Evaluating Internship Programs with vecshift

## Overview

This vignette demonstrates how to evaluate the causal impact of internship programs (C.01.00 contracts) on career trajectories using the vecshift package's comprehensive impact evaluation framework. Internships represent a critical early-career intervention that can shape long-term employment outcomes for young workers.

**What you'll learn:**

- How to identify treatment events in employment data
- Methods for creating valid control groups through matching
- Causal inference estimation techniques (DiD, Event Studies, Synthetic Control)
- Impact metrics calculation and interpretation
- Best practices for policy-relevant impact evaluation

## The Policy Question

Throughout this guide, we'll evaluate the impact of **internship programs** on career trajectories. This represents a critical career development intervention where young workers gain their first professional experience through internships, which can affect their future employment outcomes through:

- Skills development and on-the-job training
- Professional network building and employer connections  
- Signaling effects to future employers
- Potential conversion to regular employment

## Why Evaluate Internship Impact?

Internships (C.01.00 contracts) serve as a crucial bridge between education and employment. Understanding their causal impact helps:

- **Policy makers**: Design effective youth employment programs
- **Educational institutions**: Improve career placement services
- **Employers**: Assess the value of internship programs
- **Young workers**: Make informed career decisions

Key outcomes we'll measure:
- **Employment stability**: Do internships lead to more stable future employment?
- **Career progression**: Do interns advance faster in their careers?
- **Wage trajectories**: Do internships affect future earnings?
- **Job quality**: Do internships lead to better job matches?

# Data Preparation and Processing

## Step 1: Prepare Employment Data with vecshift

First, we need employment data processed through vecshift to create temporal segments with overlap consolidation:

```{r data-preparation}
# Example: Create synthetic employment data for demonstration
# In practice, you would load your actual employment dataset

# Generate sample employment records
n_people <- 200
n_contracts <- 800

# Create sample employment data
set.seed(2024)
employment_raw <- data.table(
  cf = sample(1:n_people, n_contracts, replace = TRUE),
  id = 1:n_contracts,
  INIZIO = sample(seq(as.Date("2020-01-01"), as.Date("2023-12-31"), by = "day"), 
                  n_contracts, replace = TRUE)
)

# Add end dates (contract durations between 30-730 days)
employment_raw[, FINE := INIZIO + sample(30:730, .N, replace = TRUE)]

# Add contract types: temporary (-1, 0) vs internship (1, 2, 3)  
employment_raw[, prior := sample(c(-1, 0, 1, 2, 3), .N, 
                                 replace = TRUE, prob = c(0.2, 0.3, 0.3, 0.15, 0.05))]

# Add contract type codes
employment_raw[, COD_TIPOLOGIA_CONTRATTUALE := ifelse(
  prior > 0, "C.01.00", # Internship
  sample(c("C.02.01", "C.02.02", "C.03.07"), .N, replace = TRUE) # Temporary
)]

# Add person characteristics (time-invariant)
person_chars <- data.table(
  cf = 1:n_people,
  age_baseline = sample(20:45, n_people, replace = TRUE),
  education = sample(c("High_School", "Bachelor", "Master"), n_people, 
                     replace = TRUE, prob = c(0.5, 0.35, 0.15)),
  gender = sample(c("M", "F"), n_people, replace = TRUE),
  region = sample(c("North", "Center", "South"), n_people, 
                  replace = TRUE, prob = c(0.4, 0.3, 0.3)),
  sector = sample(c("Manufacturing", "Services", "Construction", "IT"), n_people,
                  replace = TRUE, prob = c(0.3, 0.4, 0.2, 0.1))
)

# Merge with employment data
employment_raw <- merge(employment_raw, person_chars, by = "cf")

# Sort by person and date
setorder(employment_raw, cf, INIZIO)

print(paste("Created sample data with", nrow(employment_raw), "employment records for", 
            uniqueN(employment_raw$cf), "people"))
```

```{r vecshift-processing}
# Process through vecshift to create temporal segments
cat("Processing employment data through vecshift...\n")
employment_processed <- vecshift(
  employment_raw,
  classify_status = TRUE
)

cat("Original records:", nrow(employment_raw), "\n")
cat("Processed segments:", nrow(employment_processed), "\n")
cat("People with over_id > 0 (employment periods):", 
    employment_processed[over_id > 0, uniqueN(cf)], "\n")

# Display sample of processed data
head(employment_processed[, .(cf, inizio, fine, durata, over_id, arco, 
                              stato, prior)])
```

# Treatment Event Identification

## Step 2: Identify Treatment Events

Now we identify people who participated in internship programs and collect their complete employment histories:

```{r treatment-identification, eval=FALSE}
# Identify treatment events: internship participation
# This identifies people who had internships (COD_TIPOLOGIA_CONTRATTUALE == 'C.01.00')
treatment_data <- identify_treatment_events(
  data = employment_processed,
  treatment_conditions = list(
    "COD_TIPOLOGIA_CONTRATTUALE == 'C.01.00'"
  ),
  event_window = c(-365, 730), # 1 year before, 2 years after  
  min_pre_period = 90,         # At least 90 days before
  min_post_period = 90,        # At least 90 days after
  multiple_events = "first",   # Use first internship per person
  require_employment_before = TRUE,
  id_column = "cf",
  date_column = "inizio"
)

cat("Total observations (all employment events):", nrow(treatment_data), "\n")
cat("Treated people (had internships):", 
    treatment_data[is_treated == TRUE, uniqueN(cf)], "\n")
cat("Control people (never had internships):", 
    treatment_data[is_treated == FALSE, uniqueN(cf)], "\n")
cat("Treatment rate:", 
    round(mean(treatment_data$is_treated, na.rm = TRUE) * 100, 1), "%\n")
```

In practice, this would output something like:
```
Total observations (all employment events): 3247
Treated people (had internships): 45
Control people (never had internships): 155
Treatment rate: 22.5%
```

## Step 3: Assess Treatment Event Quality

```{r event-quality-assessment, eval=FALSE}
# Assess the quality of treatment event identification
event_assessment <- assess_treatment_event_quality(
  event_data = treatment_data,
  assessment_variables = c("age_baseline", "education", "sector", "region"),
  output_format = "summary"
)

# Print assessment results
print(event_assessment)
```

This would provide diagnostic information like:
```
Treatment Event Assessment
==========================

Event Summary:
  Total observations: 3247
  Treated units: 1105
  Control units: 2142
  Treatment rate: 34.06%
  Unique treated persons: 45

Recommendations:
  1. Large standardized differences detected - consider matching or stratification
```

# Control Group Construction and Matching

## Step 4: Create Treatment and Control Groups

The vecshift impact evaluation framework uses a **two-step workflow** for creating and matching treatment and control groups:

1. **Step 4a**: Create basic treatment/control groups using `create_treatment_control_groups()`
2. **Step 4b**: Apply propensity score matching using `propensity_score_matching()`

This separation ensures clean code organization and allows users to inspect groups before matching.

### Step 4a: Basic Group Creation

```{r group-creation, eval=FALSE}
# Step 4a: Create basic treatment and control groups (without matching)
groups <- create_treatment_control_groups(
  event_data = treatment_data,
  control_ratio = 2,
  exclude_future_treated = TRUE
)

cat("Treatment group size:", sum(groups$group_assignment == "treatment", na.rm = TRUE), "\n")
cat("Control group size:", sum(groups$group_assignment == "control", na.rm = TRUE), "\n")

# Display group composition
table(groups$group_assignment, useNA = "ifany")

# Important: If you accidentally provide matching_variables to this function,
# you'll see a warning like:
# "Matching variables provided but not used. For propensity score matching, 
#  use propensity_score_matching() from the impact_matching module after creating groups."
# This is normal - the function separates group creation from matching
```

## Step 4b: Propensity Score Matching

After creating basic groups, perform rigorous propensity score matching to improve causal inference:

```{r propensity-matching, eval=FALSE}
# Step 4b: Perform propensity score matching on the groups
# This is the proper way to incorporate matching variables

ps_match_result <- propensity_score_matching(
  data = groups,  # Use the groups created in Step 4a
  treatment_var = "is_treated",
  person_id_var = "cf",
  matching_variables = c("age", "education", "sector", "region"),
  exact_match_vars = c("gender"),
  method = "nearest",
  ratio = 2,
  caliper = 0.1,
  missing_data_action = "complete_cases"
)

# The result contains:
# ps_match_result$matched_data - all events for matched people
# ps_match_result$balance_before - balance before matching  
# ps_match_result$balance_after - balance after matching
# ps_match_result$match_summary - matching diagnostics

cat("Matched treatment units:", 
    sum(ps_match_result$matched_data$group_assignment == "treatment", na.rm = TRUE), "\n")
cat("Matched control units:", 
    sum(ps_match_result$matched_data$group_assignment == "control", na.rm = TRUE), "\n")

# Use the matched data for subsequent analysis
matched_data <- ps_match_result$matched_data
```

### Alternative: Coarsened Exact Matching

For categorical variables or when exact matches are preferred:

```{r cem-matching, eval=FALSE}
# Alternative matching approach using Coarsened Exact Matching
cem_result <- coarsened_exact_matching(
  data = groups,
  treatment_var = "is_treated", 
  person_id_var = "cf",
  matching_variables = c("education", "sector", "region"),
  cutpoints = list(age = c(25, 35, 45))  # Age bins
)

# CEM often provides better balance but smaller sample sizes
cat("CEM matched sample size:", nrow(cem_result$matched_data), "\n")
```

## Step 5: Assess Balance and Match Quality

```{r balance-assessment, eval=FALSE}
# Assess balance between treatment and control groups
balance_results <- assess_balance(
  matched_data = ps_match_result$matched_data,
  treatment_var = "is_treated", 
  balance_variables = c("age_baseline", "education", "sector"),
  thresholds = list(mean_diff = 0.1, variance_ratio = 2)
)

# Assess overall match quality
match_quality <- assess_match_quality(
  matching_result = ps_match_result,
  diagnostic_plots = TRUE
)

print(balance_results)
print(match_quality$quality_summary)
```

# Impact Estimation

## Step 6: Calculate Pre/Post Treatment Metrics

Calculate employment outcomes before and after treatment events:

```{r impact-metrics, eval=FALSE}
# First, create period indicators for our analysis
# Add event period indicators to our groups data
groups[, event_period := ifelse(
  !is.na(days_to_event) & days_to_event < 0, "pre", 
  ifelse(!is.na(days_to_event) & days_to_event >= 0, "post", "control")
)]

# Calculate employment stability metrics
stability_metrics <- calculate_employment_stability_metrics(
  data = groups,
  id_column = "cf",
  period_column = "event_period",
  date_column = "inizio",
  employment_indicator = "over_id",
  min_spell_duration = 7
)

# Display sample results  
head(stability_metrics[, .(cf, period, employment_rate, employment_spells, 
                          avg_employment_spell, employment_stability_index)])

# Calculate contract quality metrics
contract_metrics <- calculate_contract_quality_metrics(
  data = groups,
  id_column = "cf", 
  period_column = "event_period",
  contract_type_column = "prior",
  internship_values = c(1, 2, 3),
  temporary_values = c(-1, 0)
)

head(contract_metrics[, .(cf, period, internship_contract_rate, 
                         contract_quality_index, temp_to_perm_transitions)])
```

Example output would show:
```
     cf period employment_rate employment_spells avg_employment_spell employment_stability_index
1:    1    pre            0.85                 2               124.5                       0.73
2:    1   post            0.92                 1               290.0                       0.89
3:    5    pre            0.67                 3                87.3                       0.58
4:    5   post            0.88                 2               165.5                       0.81
```

## Step 7: Difference-in-Differences Estimation

```{r did-estimation, eval=FALSE}
# Prepare data for DiD estimation by aggregating to person-period level
did_data <- stability_metrics[period %in% c("pre", "post")]

# Add treatment indicator  
did_data <- merge(did_data, 
                  groups[, .(cf, is_treated)][!duplicated(cf)], 
                  by = "cf")

# Difference-in-differences estimation
did_results <- difference_in_differences(
  data = did_data,
  outcome_vars = c("employment_rate", "employment_stability_index"),
  treatment_var = "is_treated", 
  time_var = "period",
  id_var = "cf",
  control_vars = NULL, # Could add: c("age_baseline", "education")
  fixed_effects = "both",
  parallel_trends_test = TRUE
)

# Results would contain:
# did_results$estimates - treatment effect estimates
# did_results$parallel_trends_test - assumption test results
# did_results$summary_table - formatted results
```

## Step 8: Event Study Analysis

```{r event-study, eval=FALSE}
# Event study for dynamic treatment effects
event_study_results <- event_study_design(
  data = groups,
  outcome_vars = c("employment_rate", "contract_quality_index"),
  time_to_event_var = "days_to_event",
  treatment_var = "is_treated",
  id_var = "cf",
  event_window = c(-365, 730),
  time_unit = "months"
)

# Results would show treatment effects over time relative to treatment date
```

# Results Visualization and Interpretation

## Step 10: Visualize Results

```{r visualization, eval=FALSE}
# Plot balance assessment
balance_plot <- plot_balance_assessment(
  matching_results = ps_match_result,
  plot_type = "love",
  threshold = 0.1,
  use_bw = FALSE
)

# Plot treatment vs control comparison
comparison_plot <- plot_treatment_control_comparison(
  data = groups,
  outcome_vars = c("employment_rate", "avg_employment_spell"),
  treatment_var = "is_treated"
)

# Plot difference-in-differences results
did_plot <- plot_did_results(
  did_results = did_results,
  outcome_var = "employment_rate"
)

# Plot event study results  
event_plot <- plot_event_study(
  event_study_results = event_study_results,
  outcome_var = "employment_rate"
)

# Create comprehensive summary plot
summary_plot <- plot_impact_summary(
  treatment_data = groups,
  metrics_data = stability_metrics,
  estimation_results = did_results
)
```

# Report Generation and Export

## Step 11: Generate Comprehensive Report

```{r reporting, eval=FALSE}
# Compile all analysis results
analysis_results <- list(
  event_identification = list(
    treatment_data = treatment_data,
    event_assessment = event_assessment
  ),
  matching = list(
    matched_data = ps_match_result$matched_data,
    balance_results = balance_results,
    match_quality = match_quality
  ),
  estimation = list(
    did_results = did_results,
    event_study_results = event_study_results
  ),
  metrics = list(
    stability_metrics = stability_metrics,
    contract_metrics = contract_metrics
  )
)

# Generate comprehensive HTML report
impact_report <- generate_impact_report(
  analysis_results = analysis_results,
  output_format = "html",
  output_file = "internship_impact_evaluation",
  template = "academic",
  title = "Impact Evaluation: Internship Impact on Careers",
  include_plots = TRUE,
  include_tables = TRUE
)

# Export results for further analysis
export_impact_results(
  analysis_results = analysis_results,
  output_dir = "impact_evaluation_results",
  formats = c("csv", "xlsx", "rds")
)
```

# Methodology Summary and Best Practices

## Impact Evaluation Workflow Summary

The vecshift impact evaluation framework follows this systematic approach:

1. **Data Preparation**: Use `vecshift()` to process employment records into temporal segments with over_id consolidation

2. **Event Identification**: Use `identify_treatment_events()` to find people who experienced treatment and collect their full employment histories

3. **Quality Assessment**: Use `assess_treatment_event_quality()` to validate event identification and check for potential issues

4. **Control Group Construction**: Use `propensity_score_matching()` or `coarsened_exact_matching()` to create comparable control groups

5. **Balance Assessment**: Use `assess_balance()` and `assess_match_quality()` to ensure treatment and control groups are comparable

6. **Impact Metrics**: Use metric calculation functions to measure employment outcomes before and after treatment

7. **Causal Estimation**: Use `difference_in_differences()`, `event_study_design()`, or `synthetic_control_method()` for causal inference

8. **Visualization**: Use plotting functions to visualize results and diagnostic information

9. **Reporting**: Use `generate_impact_report()` to create comprehensive reports for stakeholders

## Key Methodological Considerations

### Treatment Event Identification

- **Person-centered approach**: The framework identifies people who experienced treatment and collects their complete employment histories
- **Multiple conditions**: Support for complex treatment definitions using multiple conditions
- **Quality assessment**: Built-in diagnostics to assess the quality of event identification

### Matching and Control Group Selection

- **Person-level matching**: Matches people (not individual employment spells) based on stable characteristics
- **Multiple methods**: Support for propensity score matching and coarsened exact matching
- **Balance assessment**: Comprehensive balance diagnostics with standardized differences and distributional tests

### Causal Inference Methods

- **Difference-in-differences**: Identifies treatment effects using variation in treatment timing
- **Event studies**: Examines dynamic treatment effects and tests parallel trends assumptions
- **Synthetic control**: Creates synthetic counterfactuals for comparison units

### Impact Metrics

- **Employment stability**: Measures employment rates, spell durations, and job turnover
- **Contract quality**: Tracks career progression after internship completion
- **Career complexity**: Analyzes concurrent employment and career fragmentation
- **Transition patterns**: Examines job search behavior and employment transitions

## Conclusion

The vecshift impact evaluation framework provides a comprehensive toolkit for rigorous impact evaluation of employment interventions. By combining the package's powerful temporal processing capabilities with specialized impact evaluation modules, researchers can conduct policy-relevant analysis that meets academic standards for causal inference.

The framework's modular design allows for flexible analysis workflows while ensuring methodological rigor through built-in diagnostics, balance assessments, and robustness checks. This makes it suitable for both academic research and policy evaluation contexts.

For more detailed information about specific functions and advanced features, consult the individual function documentation and the vecshift package reference manual.